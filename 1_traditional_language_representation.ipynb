{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9262-7pIAfJ9",
        "outputId": "ad32b9b2-ad72-4683-8709-e31a0d38fa5b"
      },
      "source": [
        "# Preprocessing and Traditional Language Representation for Text Classification using Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " This notebook explores various text representation techniques for Natural Language Processing and Information Retrieval tasks. It preprocesses a dataset of tweets, implements different vectorization methods such as:\n",
        "\n",
        "\n",
        "*   Bag of Words (binary and term-frequency)\n",
        "*   TF-IDF\n",
        "*   Bigram and trigram models\n",
        "*   Latent Semantic Analysis (LSA) with Singular Value Decomposition (SVD)\n",
        "\n",
        "\n",
        " The notebook then applies cosine similarity to analyze the similarity between sexist and non-sexist tweets. All implementations use Scikit-Learn's text processing tools."
      ],
      "metadata": {
        "id": "GRGxE3DYxclQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULkp2-R-r7Qu",
        "outputId": "61ea1742-b54f-4d4e-c3f7-86f4b028c334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfnSRvpOr7Qv"
      },
      "source": [
        "## Some help, if you need it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:06:43.865645Z",
          "start_time": "2025-02-26T19:06:43.861381Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOBlr4iUr7Qw",
        "outputId": "b5a7e809-6e82-491f-c777-43cebd93d10d"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install nltk\n",
        "!pip install scikit-learn\n",
        "\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "# from nltk.book import texts\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy16MrNbr7Qw"
      },
      "source": [
        "## Load de dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:06:47.070687Z",
          "start_time": "2025-02-26T19:06:47.039687Z"
        },
        "id": "gPyQs3Igr7Qx"
      },
      "source": [
        "filename = \"./drive/MyDrive/EXIST2024_EN_examples.csv\"\n",
        "# filename = \"EXIST2024_EN_examples.csv\"\n",
        "\n",
        "class CSVReader:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self.data = []\n",
        "\n",
        "    def read_csv(self):\n",
        "        with open(self.file_path, mode='r', encoding='utf-8') as file:\n",
        "            reader = csv.DictReader(file, delimiter='\\t')\n",
        "            for row in reader:\n",
        "                self.data.append({\n",
        "                    \"id\": int(row[\"id\"]),\n",
        "                    \"text\": row[\"text\"],\n",
        "                    \"is_sexist\": row[\"label\"].strip().upper() == \"YES\",\n",
        "                    \"size\": int(row[\"size\"])\n",
        "                })\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data\n",
        "\n",
        "reader = CSVReader(filename)\n",
        "reader.read_csv()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix595iVcr7Qx"
      },
      "source": [
        "## Preprocess dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:06:50.243249Z",
          "start_time": "2025-02-26T19:06:50.227466Z"
        },
        "id": "yma1iOqhr7Qy"
      },
      "source": [
        "web_re = re.compile(r\"https?:\\/\\/[^\\s]+\", re.U)\n",
        "\n",
        "def preprocess(text):\n",
        "    text = web_re.sub(\"\", text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "for tweet in reader.get_data():\n",
        "    tweet[\"text\"] = preprocess(tweet[\"text\"])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:10:47.623956Z",
          "start_time": "2025-02-26T19:10:47.617945Z"
        },
        "id": "X7pH3XHrr7Qz"
      },
      "cell_type": "code",
      "source": [
        "def compute_similarity(MyCorpus, bow, sexist):\n",
        "    cosine_sim = cosine_similarity(bow)\n",
        "    maxi = 0\n",
        "    max_ind = 0, 0\n",
        "\n",
        "    for x in range(len(cosine_sim)):\n",
        "        for y in range(len(cosine_sim[x])):\n",
        "            if x != y:\n",
        "                if cosine_sim[x][y] > maxi:\n",
        "                    maxi = cosine_sim[x][y]\n",
        "                    max_ind = x, y\n",
        "\n",
        "    tweet1, tweet2 = MyCorpus[max_ind[0]], MyCorpus[max_ind[1]]\n",
        "    label = \"YES\" if sexist else \"NO\"\n",
        "    print(f\"label: {label}\")\n",
        "    print(f\"1: {tweet1}\\n2: {tweet2}\")\n",
        "    print(f\"Cosine Similarity: {cosine_sim[max_ind[0]][max_ind[1]]:.4f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:10:52.155419Z",
          "start_time": "2025-02-26T19:10:49.842559Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLcERx4rr7Q0",
        "outputId": "e44282ba-273a-452a-af37-96f13da306eb"
      },
      "cell_type": "code",
      "source": [
        "print(\"Bag of Words (binary)\\n=====================\\n\")\n",
        "MyCorpus_sexist = [tweet[\"text\"] for tweet in reader.get_data() if tweet[\"is_sexist\"]]\n",
        "MyCorpus_nonsexist = [tweet[\"text\"] for tweet in reader.get_data() if not tweet[\"is_sexist\"]]\n",
        "\n",
        "vectorizer_bin = CountVectorizer(binary= True)\n",
        "vectorizer_bin.fit(MyCorpus_nonsexist)\n",
        "X_bag_of_words_bin = vectorizer_bin.transform(MyCorpus_nonsexist)\n",
        "\n",
        "compute_similarity(MyCorpus_nonsexist, X_bag_of_words_bin, False)\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "vectorizer_bin = CountVectorizer(binary= True)\n",
        "vectorizer_bin.fit(MyCorpus_sexist)\n",
        "X_bag_of_words_bin = vectorizer_bin.transform(MyCorpus_sexist)\n",
        "\n",
        "compute_similarity(MyCorpus_sexist, X_bag_of_words_bin, True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words (binary)\n",
            "=====================\n",
            "\n",
            "label: NO\n",
            "1: â™« now playing : treat her like a lady (single version) by the temptations  \n",
            "2: now playing:  the temptations - treat her like a lady   listen live: \n",
            "Cosine Similarity: 0.7628\n",
            "--------------------------------\n",
            "label: YES\n",
            "1: @yayroger @victoriarossi @ionaguyf @metsdaddy2013 @byandrewwagner @themikebpeters dr. cox, does this shade of red make me look like a clown?no barbie. it makes you look like a prostitute who caters exclusively to clowns.\n",
            "2: sharon: oh, loki, does this lipstick make me look like a clown?loki: no, barbie, no... it makes you look like a prostitute who caters exclusively *to* clowns.\n",
            "Cosine Similarity: 0.7126\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:12:56.872461Z",
          "start_time": "2025-02-26T19:12:54.333887Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO_xOGshr7Q0",
        "outputId": "0b3f8ae5-b801-49d0-c925-a5ab51a4238b"
      },
      "cell_type": "code",
      "source": [
        "print(\"Bag of Words (Term-Frequency) without normalization\\n=====================\\n\")\n",
        "vectorizer_freq = CountVectorizer(binary= False)\n",
        "vectorizer_freq.fit(MyCorpus_nonsexist)\n",
        "X_bag_of_words_freq = vectorizer_freq.transform(MyCorpus_nonsexist)\n",
        "\n",
        "compute_similarity(MyCorpus_nonsexist, X_bag_of_words_freq, False)\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "vectorizer_freq = CountVectorizer(binary= False)\n",
        "vectorizer_freq.fit(MyCorpus_sexist)\n",
        "X_bag_of_words_freq = vectorizer_freq.transform(MyCorpus_sexist)\n",
        "\n",
        "compute_similarity(MyCorpus_sexist, X_bag_of_words_freq, True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words (Term-Frequency) without normalization\n",
            "=====================\n",
            "\n",
            "label: NO\n",
            "1: @bleedthisway replay free woman breebylon &gt;&gt;&gt; flop this way\n",
            "2: replay&gt;alice&gt;babylon&gt;free woman \n",
            "Cosine Similarity: 0.7778\n",
            "--------------------------------\n",
            "label: YES\n",
            "1: @yayroger @victoriarossi @ionaguyf @metsdaddy2013 @byandrewwagner @themikebpeters dr. cox, does this shade of red make me look like a clown?no barbie. it makes you look like a prostitute who caters exclusively to clowns.\n",
            "2: sharon: oh, loki, does this lipstick make me look like a clown?loki: no, barbie, no... it makes you look like a prostitute who caters exclusively *to* clowns.\n",
            "Cosine Similarity: 0.7247\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:13:45.173677Z",
          "start_time": "2025-02-26T19:13:45.168127Z"
        },
        "id": "ZKgLfDlBr7Q1"
      },
      "cell_type": "code",
      "source": [
        "def compute_similarity2(MyCorpus, bow, sexist, representation):\n",
        "    cosine_sim = cosine_similarity(bow)\n",
        "    maxi = 0\n",
        "    max_ind = (0, 0)\n",
        "\n",
        "    for x in range(len(cosine_sim)):\n",
        "        for y in range(len(cosine_sim[x])):\n",
        "\n",
        "            if x != y and cosine_sim[x][y] > maxi:\n",
        "                maxi = cosine_sim[x][y]\n",
        "                max_ind = (x, y)\n",
        "\n",
        "    tweet1, tweet2 = MyCorpus[max_ind[0]], MyCorpus[max_ind[1]]\n",
        "    label = \"YES\" if sexist else \"NO\"\n",
        "    print(f\"label: {label}\")\n",
        "    print(f\"1: {tweet1}\\n2: {tweet2}\")\n",
        "    print(f\"Cosine Similarity: {cosine_sim[max_ind[0]][max_ind[1]]:.4f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:42:02.616433Z",
          "start_time": "2025-02-26T19:42:00.062117Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD8BZU0fr7Q1",
        "outputId": "14687765-2392-4405-b867-cb49010c382f"
      },
      "cell_type": "code",
      "source": [
        "bigram_vectorizer = CountVectorizer(analyzer='word',\n",
        "                        ngram_range=(2,2),binary=False, stop_words = None, preprocessor=None)\n",
        "\n",
        "print(\"Bigrams of Words (Term-Frequency) without normalization\\n=====================\\n\")\n",
        "counts = bigram_vectorizer.fit_transform(MyCorpus_nonsexist)\n",
        "compute_similarity2(MyCorpus_nonsexist, counts, False, \"bigrams representation\")\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "counts = bigram_vectorizer.fit_transform(MyCorpus_sexist)\n",
        "compute_similarity2(MyCorpus_sexist, counts, True, \"bigrams representation\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams of Words (Term-Frequency) without normalization\n",
            "=====================\n",
            "\n",
            "label: NO\n",
            "1: earth angel (androgynous mind) \n",
            "2: average hacker fan vs average earth angel (androgynous mind) enthusiast\n",
            "Cosine Similarity: 0.5774\n",
            "--------------------------------\n",
            "label: YES\n",
            "1: @yayroger @victoriarossi @ionaguyf @metsdaddy2013 @byandrewwagner @themikebpeters dr. cox, does this shade of red make me look like a clown?no barbie. it makes you look like a prostitute who caters exclusively to clowns.\n",
            "2: sharon: oh, loki, does this lipstick make me look like a clown?loki: no, barbie, no... it makes you look like a prostitute who caters exclusively *to* clowns.\n",
            "Cosine Similarity: 0.6124\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T19:43:06.503793Z",
          "start_time": "2025-02-26T19:43:03.781038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz10WMolr7Q1",
        "outputId": "814129d4-398f-43b8-e22f-041551a70324"
      },
      "cell_type": "code",
      "source": [
        "trigram_vectorizer = CountVectorizer(analyzer='char_wb',\n",
        "                        ngram_range=(3,3),binary = False, stop_words = None)\n",
        "\n",
        "print(\"Trigram of Words (Term-Frequency) without normalization\\n=====================\\n\")\n",
        "\n",
        "counts = trigram_vectorizer.fit_transform(MyCorpus_nonsexist)\n",
        "compute_similarity2(MyCorpus_nonsexist, counts, False, \"trigrams representation\")\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "counts = trigram_vectorizer.fit_transform(MyCorpus_sexist)\n",
        "compute_similarity2(MyCorpus_sexist, counts, True, \"trigrams representation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram of Words (Term-Frequency) without normalization\n",
            "=====================\n",
            "\n",
            "label: NO\n",
            "1: â™« now playing : treat her like a lady (single version) by the temptations  \n",
            "2: now playing:  the temptations - treat her like a lady   listen live: \n",
            "Cosine Similarity: 0.7100\n",
            "--------------------------------\n",
            "label: YES\n",
            "1: @yayroger @victoriarossi @ionaguyf @metsdaddy2013 @byandrewwagner @themikebpeters dr. cox, does this shade of red make me look like a clown?no barbie. it makes you look like a prostitute who caters exclusively to clowns.\n",
            "2: sharon: oh, loki, does this lipstick make me look like a clown?loki: no, barbie, no... it makes you look like a prostitute who caters exclusively *to* clowns.\n",
            "Cosine Similarity: 0.6660\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T20:51:30.877290Z",
          "start_time": "2025-02-26T20:51:29.207992Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2wgzEGxr7Q2",
        "outputId": "e16ddf9c-8194-4d8c-e521-14d9d950ed3c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words=None, binary=False, use_idf=True, preprocessor=None)\n",
        "\n",
        "print(\"TF-IDF based on words with 'l2' normalization \\n=====================\\n\")\n",
        "counts = tfidf_vectorizer.fit_transform(MyCorpus_nonsexist)\n",
        "compute_similarity2(MyCorpus_nonsexist, counts, False, \"\")\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "counts = tfidf_vectorizer.fit_transform(MyCorpus_sexist)\n",
        "compute_similarity2(MyCorpus_sexist, counts, True, \"\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF based on words with 'l2' normalization \n",
            "=====================\n",
            "\n",
            "label: NO\n",
            "1: @bleedthisway replay free woman breebylon &gt;&gt;&gt; flop this way\n",
            "2: replay&gt;alice&gt;babylon&gt;free woman \n",
            "Cosine Similarity: 0.7384\n",
            "--------------------------------\n",
            "label: YES\n",
            "1: @yayroger @victoriarossi @ionaguyf @metsdaddy2013 @byandrewwagner @themikebpeters dr. cox, does this shade of red make me look like a clown?no barbie. it makes you look like a prostitute who caters exclusively to clowns.\n",
            "2: sharon: oh, loki, does this lipstick make me look like a clown?loki: no, barbie, no... it makes you look like a prostitute who caters exclusively *to* clowns.\n",
            "Cosine Similarity: 0.5112\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T20:51:36.694261Z",
          "start_time": "2025-02-26T20:51:34.718667Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGUDBFHir7Q3",
        "outputId": "520a254d-0580-4474-bbf8-50af2e214ecf"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "print(\"LSA based on TF-IDF of words (50 singular values)\\n=====================\\n\")\n",
        "\n",
        "\n",
        "svd = TruncatedSVD(n_components=50)\n",
        "tfidfMatrix_nonsexist = tfidf_vectorizer.fit_transform(MyCorpus_nonsexist)\n",
        "svdMatrix_nonsexist = svd.fit_transform(tfidfMatrix_nonsexist)\n",
        "compute_similarity2(MyCorpus_nonsexist, svdMatrix_nonsexist, False, \"LSA for 50 representation\")\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "tfidfMatrix_sexist = tfidf_vectorizer.fit_transform(MyCorpus_sexist)\n",
        "svdMatrix_sexist = svd.fit_transform(tfidfMatrix_sexist)\n",
        "compute_similarity2(MyCorpus_sexist, svdMatrix_sexist, True, \"LSA for 50 representation\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA based on TF-IDF of words (50 singular values)\n",
            "=====================\n",
            "\n",
            "label: NO\n",
            "1: @mainetrendteam @mainedcm androgynous (mind).mainexlazada 1111supershow#lazadaxmaine @mainedcm #maineforlazada1111 #mainemendoza @mainedcm\n",
            "2: earth angel (androgynous mind) \n",
            "Cosine Similarity: 0.9990\n",
            "--------------------------------\n",
            "label: YES\n",
            "1: @twinklybunny perfect young body. i would like to fuck you.\n",
            "2: @misskatie2021 i would like to fuck you ðŸ˜‚ðŸ˜‚ðŸ˜‚Ã  french fan\n",
            "Cosine Similarity: 0.9859\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-02-26T20:52:08.774386Z",
          "start_time": "2025-02-26T20:52:06.400436Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc0_U29nr7Q3",
        "outputId": "b4509d85-2e75-42e0-922a-bf9358e98c10"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "print(\"LSA based on TF-IDF of words (100 singular values)\\n=====================\\n\")\n",
        "\n",
        "svd = TruncatedSVD(n_components=100)\n",
        "tfidfMatrix_nonsexist = tfidf_vectorizer.fit_transform(MyCorpus_nonsexist)\n",
        "svdMatrix_nonsexist = svd.fit_transform(tfidfMatrix_nonsexist)\n",
        "\n",
        "compute_similarity2(MyCorpus_nonsexist, svdMatrix_nonsexist, False, \"LSA for 100 representation\")\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "tfidfMatrix_sexist = tfidf_vectorizer.fit_transform(MyCorpus_sexist)\n",
        "svdMatrix_sexist = svd.fit_transform(tfidfMatrix_sexist)\n",
        "\n",
        "compute_similarity2(MyCorpus_sexist, svdMatrix_sexist, True, \"LSA for 100 representation\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA based on TF-IDF of words (100 singular values)\n",
            "=====================\n",
            "\n",
            "label: NO\n",
            "1: @mainetrendteam @mainedcm androgynous (mind).mainexlazada 1111supershow#lazadaxmaine @mainedcm #maineforlazada1111 #mainemendoza @mainedcm\n",
            "2: earth angel (androgynous mind) \n",
            "Cosine Similarity: 0.9985\n",
            "--------------------------------\n",
            "label: YES\n",
            "1: @yayroger @victoriarossi @ionaguyf @metsdaddy2013 @byandrewwagner @themikebpeters dr. cox, does this shade of red make me look like a clown?no barbie. it makes you look like a prostitute who caters exclusively to clowns.\n",
            "2: sharon: oh, loki, does this lipstick make me look like a clown?loki: no, barbie, no... it makes you look like a prostitute who caters exclusively *to* clowns.\n",
            "Cosine Similarity: 0.9745\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}