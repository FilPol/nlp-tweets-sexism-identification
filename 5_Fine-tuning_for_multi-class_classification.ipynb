{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pY2x6TJTxZ7"
   },
   "source": [
    "# Transformers: Fine-tuning for multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXw40QhNW39Z"
   },
   "source": [
    "## Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsJ-FM-GSM5S"
   },
   "source": [
    "### Experimental Setup (No Preprocessing Applied)\n",
    "\n",
    "Experiments were conducted using the following Transformer models:\n",
    "- **English**: RoBERTa-base\n",
    "- **Spanish**: `PlanTL-GOB-ES/roberta-base-bne`\n",
    "\n",
    "All models were trained using the same base set of hyperparameters:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"learning_rate\": [5e-5, 3e-5] (in some cases also 2e-5),\n",
    "  \"num_train_epochs\": 4,\n",
    "  \"per_device_train_batch_size\": [16, 32],\n",
    "  \"warmup_steps\": 100,\n",
    "  \"weight_decay\": 0.01,\n",
    "  \"early_stopping_patience\": 2,\n",
    "}\n",
    "```\n",
    "\n",
    "For each of the 4 learning rate and batch size combinations, the best-performing model based on F1 score was selected.\n",
    "\n",
    "---\n",
    "\n",
    "### **Results Overview**\n",
    "\n",
    "#### **English – Subtask 1 (Binary Classification)**\n",
    "\n",
    "- **Fine-Tuning (FT)** achieved an average F1 of **0.84**\n",
    "- **LoRA** achieved an average F1 of **0.79**\n",
    "- However, LoRA completed training in **12 minutes** vs **30 minutes** for FT  \n",
    "- That’s **94% of the performance at only 40% of the time**\n",
    "\n",
    "#### **English – Subtask 2 (Multi-Class Classification)**\n",
    "\n",
    "- **FT** slightly outperformed LoRA (avg F1: **0.250** vs **0.245**)  \n",
    "- Training times: FT took **30 minutes**, while LoRA took just **4 minutes**\n",
    "- FT performance fluctuated between **0.245–0.265**, while LoRA remained stable\n",
    "- Accuracy was similar for both methods (~**0.58**)\n",
    "\n",
    "#### **Spanish – Subtask 1 (Binary Classification)**\n",
    "\n",
    "- **Best LoRA model** outperformed the best FT model (F1: **0.86** vs **0.85**)\n",
    "- Average F1 scores were nearly identical:  \n",
    "  - LoRA: **0.8535**  \n",
    "  - FT: **0.8527**\n",
    "- However, **worst LoRA model** (F1: **0.839**) underperformed compared to **worst FT** (F1: **0.859**)  \n",
    "- Accuracy for FT was consistent (~**0.84**), while LoRA varied from **0.83–0.85**\n",
    "\n",
    "#### **Spanish – Subtask 2 (Multi-Class Classification)**\n",
    "\n",
    "- **FT had a higher average F1** (0.29 vs 0.25), largely due to one exceptional model (F1: **0.438**)  \n",
    "- Excluding that outlier, performance was comparable between FT and LoRA\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "While full fine-tuning occasionally yields slightly higher F1 scores, **LoRA offers a far more efficient training process**—both in time and resource consumption—making it significantly more practical, especially at scale. The **performance trade-off is minimal**, while **time savings are substantial**. In nearly all cases, LoRA models delivered results comparable to FT in a fraction of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBMTOhbPTxZ_"
   },
   "source": [
    "## Many libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Xc4hisRSCXf",
    "outputId": "a1e22271-c46f-4bbb-fded-b702a04a98e8"
   },
   "outputs": [],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install datasets accelerate --upgrade\n",
    "!pip install peft --upgrade\n",
    "!pip install jupyter --upgrade\n",
    "!pip install ipywidgets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3nZMJDIPIr3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import  AutoTokenizer, AutoModelForSequenceClassification,  Trainer, TrainingArguments,  EarlyStoppingCallback\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tempfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4-2w1O_VMlq"
   },
   "outputs": [],
   "source": [
    "# IF YOU USE GOOGLE COLAB -> COLAB=True\n",
    "COLAB = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWFD-ndKSkxp",
    "outputId": "16813719-9313-490d-e7df-abdebc5c4ba3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "NdNQeTP1UD7n",
    "outputId": "1329ba44-5c49-4434-f820-2925a32fadab"
   },
   "outputs": [],
   "source": [
    "# if COLAB is True:\n",
    "#   from google.colab import drive\n",
    "#   drive.mount('/content/drive')\n",
    "#   base_path = \"/content/drive/MyDrive/docencia/LNR/LNR_2024-2025/Lab2\"\n",
    "# else:\n",
    "#   base_path = \"..\"\n",
    "# base_path\n",
    "\n",
    "# from google.colab import userdata\n",
    "# userdata.get('HuggingFaceToken')\n",
    "\n",
    "if COLAB is True:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  base_path = \"/content/drive/MyDrive/NLP\"\n",
    "else:\n",
    "  base_path = \"..\"\n",
    "base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLdRBXFmTxaA"
   },
   "source": [
    "## Import readerEXIST2025 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqRGK4XOTxaA",
    "outputId": "44a69828-c146-4077-e330-7b0489c0c6a6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "base_path = \"drive/MyDrive/NLP\"\n",
    "sys.path.append(base_path)\n",
    "from readerEXIST2025 import EXISTReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5S9A-DcoTxaB"
   },
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chPElJ_DPEKK"
   },
   "outputs": [],
   "source": [
    "file_train = os.path.join(base_path, \"EXIST2025_training.json\")\n",
    "file_dev = os.path.join(base_path, \"EXIST2025_dev.json\")\n",
    "\n",
    "reader_train = EXISTReader(file_train)\n",
    "reader_dev = EXISTReader(file_dev)\n",
    "\n",
    "EnTrainTask1, EnDevTask1 = reader_train.get(lang=\"EN\", subtask=\"1\"), reader_dev.get(lang=\"EN\", subtask=\"1\")\n",
    "EnTrainTask2, EnDevTask2 = reader_train.get(lang=\"EN\", subtask=\"2\"), reader_dev.get(lang=\"EN\", subtask=\"2\")\n",
    "\n",
    "SpTrainTask1, SpDevTask1 = reader_train.get(lang=\"ES\", subtask=\"1\"), reader_dev.get(lang=\"ES\", subtask=\"1\")\n",
    "SpTrainTask2, SpDevTask2 = reader_train.get(lang=\"ES\", subtask=\"2\"), reader_dev.get(lang=\"ES\", subtask=\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoysIA2BTxaB"
   },
   "source": [
    "## Set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2Ti1iWiTxaB"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=1234):\n",
    "    \"\"\"\n",
    "    Sets the seed to make everything deterministic, for reproducibility of experiments\n",
    "    Parameters:\n",
    "    seed: the number to set the seed to\n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    # Random seed\n",
    "    random.seed(seed)\n",
    "    # Numpy seed\n",
    "    np.random.seed(seed)\n",
    "    # Torch seed\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # os seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpdzjIiLTxaC"
   },
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h49Be6h_SBLS"
   },
   "outputs": [],
   "source": [
    "class SexismDataset(Dataset):\n",
    "    def __init__(self, texts, labels, ids, tokenizer, max_len=128, pad=\"max_length\", trunc=True,rt='pt'):\n",
    "        self.texts = texts.tolist()\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad = pad\n",
    "        self.trunc = trunc\n",
    "        self.rt = rt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,padding=self.pad, truncation=self.trunc,\n",
    "            return_tensors=self.rt\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "            'id': torch.tensor(self.ids[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxKRdDCGTxaC"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvG7aD_8PJK2"
   },
   "outputs": [],
   "source": [
    "def compute_metrics_1(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='binary', zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def compute_metrics_2(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='macro', zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO0fXn9jTxaC"
   },
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3Zqi59laK6b"
   },
   "outputs": [],
   "source": [
    "def sexism_classification_pipeline_task1(trainInfo, devInfo, testInfo=None, model_name='roberta-base', nlabels=2, ptype=\"single_label_classification\", **args):\n",
    "    # Model and Tokenizer\n",
    "    labelEnc= LabelEncoder()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=nlabels,\n",
    "        problem_type=ptype,\n",
    "    )\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = SexismDataset(trainInfo[1], labelEnc.fit_transform(trainInfo[2]),[int(x) for x in trainInfo[0]], tokenizer )\n",
    "    val_dataset = SexismDataset(devInfo[1], labelEnc.transform(devInfo[2]), [int(x) for x in devInfo[0]], tokenizer)\n",
    "\n",
    "    # Training Arguments\n",
    "    training_args = TrainingArguments(\n",
    "        report_to=\"none\", # alt: \"wandb\", \"tensorboard\" \"comet_ml\" \"mlflow\" \"clearml\"\n",
    "        output_dir= args.get('output_dir', './results'),\n",
    "        num_train_epochs= args.get('num_train_epochs', 5),\n",
    "        learning_rate=args.get('learning_rate', 5e-5),\n",
    "        per_device_train_batch_size=args.get('per_device_train_batch_size', 16),\n",
    "        per_device_eval_batch_size=args.get('per_device_eval_batch_size', 64),\n",
    "        warmup_steps=args.get('warmup_steps', 500),\n",
    "        weight_decay=args.get('weight_decay',0.01),\n",
    "        logging_dir=args.get('logging_dir', './logs'),\n",
    "        logging_steps=args.get('logging_steps', 10),\n",
    "        eval_strategy=args.get('eval_strategy','epoch'),\n",
    "        save_strategy=args.get('save_strategy', \"epoch\"),\n",
    "        load_best_model_at_end=args.get('load_best_model_at_end', True),\n",
    "        metric_for_best_model=args.get('metric_for_best_model',\"f1\")\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics_1,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=args.get(\"early_stopping_patience\",3))]\n",
    "    )\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(\"Validation Results:\", eval_results)\n",
    "\n",
    "    # If there is a test dataset\n",
    "    if testInfo is not None:\n",
    "        # Prepare test dataset for prediction\n",
    "        test_dataset = SexismDataset(testInfo[1], [0] * len(testInfo[1]),  [int(x) for x in testInfo[0]],   tokenizer)\n",
    "\n",
    "        # Predict test set labels\n",
    "        predictions = trainer.predict(test_dataset)\n",
    "        predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "        # Create submission DataFrame\n",
    "        submission_df = pd.DataFrame({\n",
    "            'id': testInfo[0],\n",
    "            'label': labelEnc.inverse_transform(predicted_labels),\n",
    "            \"test_case\": [\"EXIST2025\"]*len(predicted_labels)\n",
    "        })\n",
    "        submission_df.to_csv('sexism_predictions_task1.csv', index=False)\n",
    "        print(\"Prediction for TASK 1 completed. Results saved to sexism_predictions_task1.csv\")\n",
    "        return model, submission_df\n",
    "    return model, eval_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hI3NZaCzqZl"
   },
   "source": [
    "###Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TPeGxbmzn9E"
   },
   "outputs": [],
   "source": [
    "def sexism_classification_pipeline_task2(trainInfo, devInfo, testInfo=None, model_name='bert-base-uncased', nlabels=3, ptype=\"single_label_classification\", **args):\n",
    "    # Model and Tokenizer\n",
    "    labelEnc= LabelEncoder()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=nlabels,\n",
    "        problem_type=ptype\n",
    "    )\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = SexismDataset(trainInfo[1], labelEnc.fit_transform(trainInfo[2]),[int(x) for x in trainInfo[0]], tokenizer )\n",
    "    # val_dataset = SexismDataset(devInfo[1], labelEnc.transform(devInfo[2]), [int(x) for x in devInfo[0]], tokenizer)\n",
    "\n",
    "    # Encode validation labels safely\n",
    "    val_labels_raw = devInfo[2]\n",
    "    val_labels_safe = []\n",
    "    val_texts_safe = []\n",
    "    val_ids_safe = []\n",
    "\n",
    "    for text, label, id_ in zip(devInfo[1], val_labels_raw, devInfo[0]):\n",
    "        if label in labelEnc.classes_:\n",
    "            val_labels_safe.append(labelEnc.transform([label])[0])\n",
    "            val_texts_safe.append(text)\n",
    "            val_ids_safe.append(int(id_))\n",
    "        else:\n",
    "            print(f\"[Warning] Unknown label in dev set: {label} — skipping\")\n",
    "\n",
    "    val_dataset = SexismDataset(val_texts_safe, val_labels_safe, val_ids_safe, tokenizer)\n",
    "\n",
    "    # Training Arguments\n",
    "    training_args = TrainingArguments(\n",
    "        report_to=\"none\", # alt: \"wandb\", \"tensorboard\" \"comet_ml\" \"mlflow\" \"clearml\"\n",
    "        output_dir= args.get('output_dir', './results'),\n",
    "        num_train_epochs= args.get('num_train_epochs', 5),\n",
    "        learning_rate=args.get('learning_rate', 5e-5),\n",
    "        per_device_train_batch_size=args.get('per_device_train_batch_size', 16),\n",
    "        per_device_eval_batch_size=args.get('per_device_eval_batch_size', 64),\n",
    "        warmup_steps=args.get('warmup_steps', 500),\n",
    "        weight_decay=args.get('weight_decay',0.01),\n",
    "        logging_dir=args.get('logging_dir', './logs'),\n",
    "        logging_steps=args.get('logging_steps', 10),\n",
    "        eval_strategy=args.get('eval_strategy','epoch'),\n",
    "        save_strategy=args.get('save_strategy', \"epoch\"),\n",
    "        save_total_limit=args.get('save_total_limit', 1),\n",
    "        load_best_model_at_end=args.get('load_best_model_at_end', True),\n",
    "        #metric_for_best_model=args.get('metric_for_best_model',\"ICM\")\n",
    "        metric_for_best_model=args.get('metric_for_best_model',\"f1\")\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics_2,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=args.get(\"early_stopping_patience\",3))]\n",
    "    )\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(\"Validation Results:\", eval_results)\n",
    "\n",
    "    # If there is a test dataset\n",
    "    if testInfo is not None:\n",
    "        # Prepare test dataset for prediction\n",
    "        test_dataset = SexismDataset(testInfo[1], [0] * len(testInfo[1]),  [int(x) for x in testInfo[0]],   tokenizer)\n",
    "\n",
    "        # Predict test set labels\n",
    "        predictions = trainer.predict(test_dataset)\n",
    "        predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "        # Create submission DataFrame\n",
    "        submission_df = pd.DataFrame({\n",
    "            'id': testInfo[0],\n",
    "            'label': labelEnc.inverse_transform(predicted_labels),\n",
    "            \"test_case\": [\"EXIST2025\"]*len(predicted_labels)\n",
    "\n",
    "        })\n",
    "        submission_df.to_csv('sexism_predictions_task2.csv', index=False)\n",
    "        print(\"Prediction TASK2 completed. Results saved to sexism_predictions_task2.csv\")\n",
    "        return model, submission_df\n",
    "    return model, eval_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epNAFC0vTxaD"
   },
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FOPTji2Wywi",
    "outputId": "1fe36d69-594d-4bca-97e9-108c7079b67b"
   },
   "source": [
    "## LoRA pipeline subtask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtaIEIvtWz8F"
   },
   "outputs": [],
   "source": [
    "######################################CHANGE###############################################\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "###########################################################################################\n",
    "def sexism_classification_pipeline_task1_LoRA(trainInfo, devInfo, testInfo=None, model_name='roberta-base', nlabels=2, ptype=\"single_label_classification\", **args):\n",
    "    # Model and Tokenizer\n",
    "    labelEnc = LabelEncoder()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=nlabels,\n",
    "        problem_type=ptype\n",
    "    )\n",
    "\n",
    "    ######################################CHANGE###############################################\n",
    "    # Configure LoRA\n",
    "    lora_config = LoraConfig(\n",
    "    task_type= args.get(\"task_type\", TaskType.SEQ_CLS),\n",
    "    target_modules= args.get(\"target_modules\", [\"query\", \"value\"]),\n",
    "    r= args.get(\"rank\", 64),  # Rank of LoRA adaptation\n",
    "    lora_alpha=args.get(\"lora_alpha\", 32),  # Scaling factor\n",
    "    lora_dropout=args.get(\"lora_dropout\", 0.1),\n",
    "    bias=args.get(\"bias\", \"none\")\n",
    ")\n",
    "    ###########################################################################################\n",
    "\n",
    "    ######################################CHANGE###############################################\n",
    "    # Prepare LoRA model\n",
    "    peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "    ###########################################################################################\n",
    "    # Prepare datasets\n",
    "    train_dataset = SexismDataset(trainInfo[1], labelEnc.fit_transform(trainInfo[2]),[int(x) for x in trainInfo[0]], tokenizer )\n",
    "    val_dataset = SexismDataset(devInfo[1], labelEnc.transform(devInfo[2]), [int(x) for x in devInfo[0]], tokenizer)\n",
    "\n",
    "    # Training Arguments\n",
    "    training_args = TrainingArguments(\n",
    "        report_to=\"none\", # alt: \"wandb\", \"tensorboard\" \"comet_ml\" \"mlflow\" \"clearml\"\n",
    "        output_dir= args.get('output_dir', './results_task1_LoRA0'),\n",
    "        num_train_epochs= args.get('num_train_epochs', 5),\n",
    "        learning_rate=args.get('learning_rate', 5e-5),\n",
    "        per_device_train_batch_size=args.get('per_device_train_batch_size', 16),\n",
    "        per_device_eval_batch_size=args.get('per_device_eval_batch_size', 64),\n",
    "        warmup_steps=args.get('warmup_steps', 500),\n",
    "        weight_decay=args.get('weight_decay',0.01),\n",
    "        logging_dir=args.get('logging_dir', './logs'),\n",
    "        logging_steps=args.get('logging_steps', 10),\n",
    "        eval_strategy=args.get('eval_strategy','epoch'),\n",
    "        save_strategy=args.get('save_strategy', \"epoch\"),\n",
    "        save_total_limit=args.get('save_total_limit', 1),\n",
    "        load_best_model_at_end=args.get('load_best_model_at_end', True),\n",
    "        metric_for_best_model=args.get('metric_for_best_model',\"f1\")\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        ######################################CHANGE###############################################\n",
    "        # Prepare LoRA model\n",
    "        model=peft_model,\n",
    "        ###########################################################################################\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics_1,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=args.get(\"early_stopping_patience\",3))]\n",
    "    )\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(\"Validation Results:\", eval_results)\n",
    "\n",
    "    ######################################CHANGE###############################################\n",
    "    #Saving the new weigths for the LoRA model\n",
    "    trainer.save_model('./final_best_model_LoRA')\n",
    "    # Notice that, in this case only the LoRA matrices are saved.\n",
    "    # The weigths for the classification head are not saved.\n",
    "    ###########################################################################################\n",
    "\n",
    "    ######################################CHANGE###############################################\n",
    "    #Mixing the LoRA matrices with the weigths of the base model used\n",
    "    mixModel=peft_model.merge_and_unload()\n",
    "    mixModel.save_pretrained(\"./final_best_model_mixpeft\")\n",
    "    # IN this case the full model is saved.\n",
    "    ###########################################################################################\n",
    "\n",
    "    if testInfo is not None:\n",
    "        # Prepare test dataset for prediction\n",
    "        test_dataset = SexismDataset(testInfo[1], [0] * len(testInfo[1]),  [int(x) for x in testInfo[0]],   tokenizer)\n",
    "\n",
    "        # Predict test set labels\n",
    "        predictions = trainer.predict(test_dataset)\n",
    "        predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "        # Create submission DataFrame\n",
    "        submission_df = pd.DataFrame({\n",
    "            'id': testInfo[0],\n",
    "            'label': labelEnc.inverse_transform(predicted_labels),\n",
    "            \"test_case\": [\"EXIST2025\"]*len(predicted_labels)\n",
    "        })\n",
    "        submission_df.to_csv('sexism_predictions_task1.csv', index=False)\n",
    "        print(\"Prediction for TASK 1 completed. Results saved to sexism_predictions_task1.csv\")\n",
    "        return model, submission_df\n",
    "    return model, eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXR31BUOTxaE"
   },
   "source": [
    "## LoRA pipeline subtask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kU5zKWoqTxaE"
   },
   "outputs": [],
   "source": [
    "######################################CHANGE###############################################\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "###########################################################################################\n",
    "def sexism_classification_pipeline_task2_LoRA(trainInfo, devInfo, testInfo=None, model_name='roberta-base', nlabels=3, ptype=\"single_label_classification\", **args):\n",
    "    # Model and Tokenizer\n",
    "    labelEnc = LabelEncoder()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=nlabels,\n",
    "        problem_type=ptype\n",
    "    )\n",
    "    ######################################CHANGE###############################################\n",
    "    # Configure LoRA\n",
    "    lora_config = LoraConfig(\n",
    "    task_type= args.get(\"task_type\", TaskType.SEQ_CLS),\n",
    "    target_modules= args.get(\"target_modules\", [\"query\", \"value\"]),\n",
    "    r= args.get(\"rank\", 64),  # Rank of LoRA adaptation\n",
    "    lora_alpha=args.get(\"lora_alpha\", 32),  # Scaling factor\n",
    "    lora_dropout=args.get(\"lora_dropout\", 0.1),\n",
    "    bias=args.get(\"bias\", \"none\"),\n",
    ")\n",
    "    ###########################################################################################\n",
    "\n",
    "    ######################################CHANGE###############################################\n",
    "    # Prepare LoRA model\n",
    "    peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "    ###########################################################################################\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = SexismDataset(trainInfo[1], labelEnc.fit_transform(trainInfo[2]),[int(x) for x in trainInfo[0]], tokenizer )\n",
    "    val_dataset = SexismDataset(devInfo[1], labelEnc.transform(devInfo[2]), [int(x) for x in devInfo[0]], tokenizer)\n",
    "\n",
    "    # Training Arguments\n",
    "    training_args = TrainingArguments(\n",
    "        report_to=\"none\", # alt: \"wandb\", \"tensorboard\" \"comet_ml\" \"mlflow\" \"clearml\"\n",
    "        output_dir= args.get('output_dir', './results_task2_LoRA0'),\n",
    "        num_train_epochs= args.get('num_train_epochs', 5),\n",
    "        learning_rate=args.get('learning_rate', 5e-5),\n",
    "        per_device_train_batch_size=args.get('per_device_train_batch_size', 16),\n",
    "        per_device_eval_batch_size=args.get('per_device_eval_batch_size', 64),\n",
    "        warmup_steps=args.get('warmup_steps', 500),\n",
    "        weight_decay=args.get('weight_decay',0.01),\n",
    "        logging_dir=args.get('logging_dir', './logs'),\n",
    "        logging_steps=args.get('logging_steps', 10),\n",
    "        eval_strategy=args.get('eval_strategy','epoch'),\n",
    "        save_strategy=args.get('save_strategy', \"epoch\"),\n",
    "        save_total_limit=args.get('save_total_limit', 1),\n",
    "        load_best_model_at_end=args.get('load_best_model_at_end', True),\n",
    "        metric_for_best_model=args.get('metric_for_best_model',\"f1\")\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        ######################################CHANGE###############################################\n",
    "        # Prepare LoRA model\n",
    "        model=peft_model,\n",
    "        ###########################################################################################\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics_2,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=args.get(\"early_stopping_patience\",3))]\n",
    "    )\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(\"Validation Results:\", eval_results)\n",
    "\n",
    "    ######################################CHANGE###############################################\n",
    "    #Saving the new weigths for the LoRA model\n",
    "    trainer.save_model('./final_best_model_LoRA')\n",
    "    # Notice that, in this case only the LoRA matrices are saved.\n",
    "    # The weigths for the classification head are not saved.\n",
    "    ###########################################################################################\n",
    "\n",
    "    ######################################CHANGE###############################################\n",
    "    #Mixing the LoRA matrices with the weigths of the base model used\n",
    "    mixModel=peft_model.merge_and_unload()\n",
    "    mixModel.save_pretrained(\"./final_best_model_mixpeft\")\n",
    "    # IN this case the full model is saved.\n",
    "    ###########################################################################################\n",
    "\n",
    "    if testInfo is not None:\n",
    "        # Prepare test dataset for prediction\n",
    "        test_dataset = SexismDataset(testInfo[1], [0] * len(testInfo[1]),  [int(x) for x in testInfo[0]],   tokenizer)\n",
    "\n",
    "        # Predict test set labels\n",
    "        predictions = trainer.predict(test_dataset)\n",
    "        predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "        # Create submission DataFrame\n",
    "        submission_df = pd.DataFrame({\n",
    "            'id': testInfo[0],\n",
    "            'label': labelEnc.inverse_transform(predicted_labels),\n",
    "            \"test_case\": [\"EXIST2025\"]*len(predicted_labels)\n",
    "        })\n",
    "        submission_df.to_csv('sexism_predictions_task2.csv', index=False)\n",
    "        print(\"Prediction for TASK 2 completed. Results saved to sexism_predictions_task1.csv\")\n",
    "        return model, submission_df\n",
    "    return model, eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1unnHjrWkR6h"
   },
   "source": [
    "# Experimental work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo56B0uKTxaD"
   },
   "source": [
    "## English, subtask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u8zFf6IJEPsS",
    "outputId": "f77b07f0-c77f-404d-8b56-0e6e6c51b8bb"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "learning_rates = [5e-5, 3e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "results_en_task1 = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "        }\n",
    "        modelname = \"roberta-base\"\n",
    "        m, res = sexism_classification_pipeline_task1(EnTrainTask1, EnDevTask1, None, modelname, 2, \"single_label_classification\", **params )\n",
    "        results_en_task1.append({\"lr\": lr, \"batch_size\": bs, \"result\": res})\n",
    "        print(f\"lr: {lr}, bs: {bs}, res: {res}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpUMJxbZTxaD"
   },
   "source": [
    "## English, subtask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkfJ9KWTD0pS",
    "outputId": "779252df-83d9-46f6-e933-465567a43dc4"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "learning_rates = [5e-5, 3e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "results_en_task2 = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "        }\n",
    "        modelname = \"roberta-base\"\n",
    "        m, res = sexism_classification_pipeline_task2(EnTrainTask2, EnDevTask2, None, modelname, 3, \"single_label_classification\", **params)\n",
    "        results_en_task2.append({\"lr\": lr, \"batch_size\": bs, \"result\": res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxVZ5nxgTxaE"
   },
   "source": [
    "## English with LoRA, subtask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SF6O2b_R-aCG",
    "outputId": "a9f98d40-327b-48ca-f30c-4bf8f632cc5b"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "learning_rates = [5e-5, 3e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "results_en_task1_lora = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "            \"use_lora\": True,\n",
    "        }\n",
    "        modelname = \"roberta-base\"\n",
    "        m, res = sexism_classification_pipeline_task1_LoRA(EnTrainTask1, EnDevTask1, None, modelname, 2, \"single_label_classification\", **params)\n",
    "        results_en_task1_lora.append({\"lr\": lr, \"batch_size\": bs, \"result\": res})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWBK9dEgHYlk"
   },
   "source": [
    "## English with LoRA, subtask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cgbWqYhTTxaE",
    "outputId": "c3e38b5b-b7fc-4e3c-d1d6-6c71d7c5d11a"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "results_en_task2_lora = []\n",
    "\n",
    "learning_rates = [5e-5, 3e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "            \"use_lora\": True,\n",
    "        }\n",
    "        modelname = \"roberta-base\"\n",
    "        m, res = sexism_classification_pipeline_task2_LoRA(EnTrainTask2, EnDevTask2, None, modelname, 5 , \"single_label_classification\", **params)\n",
    "        results_en_task2_lora.append({\"lr\": lr, \"batch_size\": bs, \"result\": res})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Htjlp9KyVLn6"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel # importing the PeftModel class\n",
    "# The model can be loadded in a simple way.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./final_best_model_mixpeft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlvo7mYYTxaE"
   },
   "source": [
    "# Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raGhh23DwTg8"
   },
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-Oy5uA6zTxaF",
    "outputId": "034e8f12-df87-415b-eac8-3aa948a2dbee"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "learning_rates = [5e-5, 3e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "results_es_task1 = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "            \"use_lora\": True,\n",
    "        }\n",
    "        modelname = \"PlanTL-GOB-ES/roberta-base-bne\"\n",
    "        m, res = sexism_classification_pipeline_task1(SpTrainTask1, SpDevTask1, None, modelname, 2, \"single_label_classification\", **params )\n",
    "        results_es_task1.append({\"lr\": lr, \"batch_size\": bs, \"result\": res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQxIPCXSwYBX"
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-B0G7UJwcXu",
    "outputId": "7926844f-5795-42a2-c4bb-14a5788d297c"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "learning_rates = [5e-5, 3e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "results_es_task2 = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "        }\n",
    "        modelname = \"PlanTL-GOB-ES/roberta-base-bne\"\n",
    "        m, res = sexism_classification_pipeline_task2(SpTrainTask2, SpDevTask2, None, modelname, 3, \"single_label_classification\", **params)\n",
    "        results_es_task2.append((lr, bs, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giI1llx31km3"
   },
   "source": [
    "# Task 1 - Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HMOqbEQz1dk9",
    "outputId": "bfba32da-5af3-4cc8-9686-51bde4db34c0"
   },
   "outputs": [],
   "source": [
    "learning_rates = [5e-5, 3e-5, 2e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "results_es_task1_lora = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "            \"use_lora\": True,\n",
    "        }\n",
    "        modelname = \"PlanTL-GOB-ES/roberta-base-bne\"\n",
    "        m, res = sexism_classification_pipeline_task1_LoRA(SpTrainTask1, SpDevTask1, None, modelname, 2, \"single_label_classification\", **params)\n",
    "        results_es_task1_lora.append({\"lr\": lr, \"batch_size\": bs, \"result\": res})\n",
    "        print(f\"ES Task1 | LR: {lr}, BS: {bs}, Result: {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPP85FZ92Pzr"
   },
   "source": [
    "# Task 2 - Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afgCM3MG10-R",
    "outputId": "0f661f2e-23ab-496e-936f-e92c012c46e3"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "results_es_task2_lora = []\n",
    "learning_rates = [5e-5, 3e-5]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        params = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_train_epochs\": 4,\n",
    "            \"per_device_train_batch_size\": bs,\n",
    "            \"warmup_steps\": 100,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"early_stopping_patience\": 2,\n",
    "            \"use_lora\": True,\n",
    "        }\n",
    "        modelname = \"PlanTL-GOB-ES/roberta-base-bne\"\n",
    "        m, res = sexism_classification_pipeline_task2_LoRA(SpTrainTask2, SpDevTask2, None, modelname, 5, \"single_label_classification\", **params)\n",
    "        results_es_task2_lora.append({\"lr\": lr, \"batch_size\": bs, \"result\": res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzSMyr9ITxaF"
   },
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPijJT9qNlQx"
   },
   "source": [
    "## Evaluate - function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icMUXFxNTxaF"
   },
   "outputs": [],
   "source": [
    "def evaluate(results):\n",
    "  best = 0.0\n",
    "  best_params = 0, 0\n",
    "\n",
    "  worst = 10\n",
    "  worst_params = 0, 0\n",
    "\n",
    "  avg = 0.0\n",
    "\n",
    "  for mod_res in results:\n",
    "      val = mod_res[\"result\"][\"eval_f1\"]\n",
    "      if val > best:\n",
    "        best = val\n",
    "        best_params = mod_res[\"batch_size\"], mod_res[\"lr\"]\n",
    "      if val < worst:\n",
    "        worst = val\n",
    "        worst_params = mod_res[\"batch_size\"], mod_res[\"lr\"]\n",
    "       # {mod_res['lr']}, batch size: {mod_res['batch_size']},\n",
    "      print(f\"f1: {mod_res['result']['eval_f1']}, accuracy: {mod_res['result']['eval_accuracy']}\")\n",
    "      avg += val\n",
    "\n",
    "  return avg / len(results), best, worst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwNzOJjnNMev"
   },
   "source": [
    "## Results - Subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DHv5f4U7zQn",
    "outputId": "e3a905d9-dfb3-4808-e75c-1813ffb4becc"
   },
   "outputs": [],
   "source": [
    "print(f\"English - Fine-tuning - Subtask 1\")\n",
    "avg, best, best_params, worst, worst_params = evaluate(results_en_task1)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best} with these params (bs, lr): {best_params}\")\n",
    "print(f\"Worst: {worst} with these params (bs, lr): {worst_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLNxEj2rM2Ai",
    "outputId": "8a1828c3-3d64-4b08-a088-59a8e30b350b"
   },
   "outputs": [],
   "source": [
    "print(f\"English - LORA - Subtask 1\")\n",
    "avg, best, best_params, worst, worst_params = evaluate(results_en_task1_lora)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best} with these params (bs, lr): {best_params}\")\n",
    "print(f\"Worst: {worst} with these params (bs, lr): {worst_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AT2CSobAM3Fj",
    "outputId": "469e1d54-2acf-4e2f-c28e-b87db9bbf8be"
   },
   "outputs": [],
   "source": [
    "print(f\"Spanish - Fine-tuning - Subtask 1\")\n",
    "avg, best, best_params, worst, worst_params = evaluate(results_es_task1)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best} with these params (bs, lr): {best_params}\")\n",
    "print(f\"Worst: {worst} with these params (bs, lr): {worst_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnFuTQA6M3xn",
    "outputId": "991ef219-b59f-43f9-86b4-24f95570699e"
   },
   "outputs": [],
   "source": [
    "print(f\"Spanish - LORA - Subtask 1\")\n",
    "avg, best, best_params, worst, worst_params = evaluate(results_es_task1_lora)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best} with these params (bs, lr): {best_params}\")\n",
    "print(f\"Worst: {worst} with these params (bs, lr): {worst_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9Jeqr64NEDY"
   },
   "source": [
    "## Results - Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vs1_Fe0UM-hf",
    "outputId": "7a15281c-77c4-457a-a3db-7a07edd459ca"
   },
   "outputs": [],
   "source": [
    "print(f\"English - Fine-tuning - Subtask 2\")\n",
    "avg, best, worst = evaluate(results_en_task2)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best}\")\n",
    "print(f\"Worst: {worst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYigMXZeM_tW",
    "outputId": "bf0af04c-4736-4e39-d9b2-4f69ac1c0429"
   },
   "outputs": [],
   "source": [
    "print(f\"English - LORA - Subtask 2\")\n",
    "avg, best, worst = evaluate(results_en_task2_lora)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best}\")\n",
    "print(f\"Worst: {worst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqfl2OQyNBR3",
    "outputId": "3c568597-c2b5-49f2-c91a-e8a0518e50fe"
   },
   "outputs": [],
   "source": [
    "print(f\"Spanish - Fine-tuning - Subtask 2\")\n",
    "avg, best, worst = evaluate(results_es_task2)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best}\")\n",
    "print(f\"Worst: {worst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99hz6BxONCmu",
    "outputId": "7a8d21fb-cc41-4bb2-b6c8-b1465fe92b17"
   },
   "outputs": [],
   "source": [
    "print(f\"Spanish - LORA - Subtask 2\")\n",
    "avg, best, worst = evaluate(results_es_task2_lora)\n",
    "print(f\"Average F1: {avg}\")\n",
    "print(f\"Best: {best}\")\n",
    "print(f\"Worst: {worst}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RoysIA2BTxaB",
    "gpdzjIiLTxaC",
    "JxKRdDCGTxaC",
    "1hI3NZaCzqZl",
    "epNAFC0vTxaD",
    "AXR31BUOTxaE",
    "raGhh23DwTg8",
    "GzSMyr9ITxaF"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
