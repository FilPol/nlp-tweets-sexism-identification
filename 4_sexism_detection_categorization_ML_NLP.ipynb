{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJDIGCUGi1Mr"
   },
   "source": [
    "#  Sexism Detection and Categorization in Tweets Using Machine Learning and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4e6q-bDi1Mz"
   },
   "source": [
    "This project aims to detect sexism in tweets and classify it into specific categories using machine learning models and NLP techniques. The task is divided into two subtasks:\n",
    "\n",
    "* Sexism Detection – Identifying whether a tweet contains sexist content.\n",
    "\n",
    "* Sexism Categorization – Classifying detected sexism into four categories: 'JUDGEMENTAL', 'REPORTED', 'DIRECT', and 'UNKNOWN'.\n",
    "\n",
    "It compares:\n",
    "* Contextual embeddings using RoBERTa\n",
    "* LSA based on TF-IDF of words (50 singular values)\n",
    "\n",
    "as feature extraction methods. Three classifiers:\n",
    "* Logistic regresion - l2 penalty, liblinear solver and 200 iterations\n",
    "* Decision tree - with default hyperparameters. I tried multiple max_depths, min_sample_split, min_samples_leaf, but default one worked the best\n",
    "* MultiLayerPerceptron - 2 hidden layers (256, 128), ReLu activation, 1500 iterations, but with early stopping, if the learning stops. I am using lbfgs solver (tried adam, but lbfgs works better), learning rate is pretty low, just 0.0005\n",
    "\n",
    "are trained and evaluated to identify sexist content. The dataset consists of English and Spanish tweets labeled for different levels of sexism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uexir0NmwwBi",
    "outputId": "7ab01ec9-3773-4193-eb79-894e589a1f39"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwOU1bBcNDG9",
    "outputId": "e8360864-7a1b-417e-83fb-59461f02f303"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDZQex2oJYzk"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive')\n",
    "\n",
    "\n",
    "from readerEXIST2025 import EXISTReader\n",
    "\n",
    "# reader_train = EXISTReader(\"EXIST2025_training.json\")\n",
    "# reader_dev = EXISTReader(\"EXIST2025_dev.json\")\n",
    "reader_train = EXISTReader(\"drive/MyDrive/EXIST2025_training.json\")\n",
    "reader_dev = EXISTReader(\"drive/MyDrive/EXIST2025_dev.json\")\n",
    "\n",
    "EnTrainTask1, EnDevTask1 = reader_train.get(lang=\"EN\", subtask=\"1\"), reader_dev.get(lang=\"EN\", subtask=\"1\")\n",
    "EnTrainTask2, EnDevTask2 = reader_train.get(lang=\"EN\", subtask=\"2\"), reader_dev.get(lang=\"EN\", subtask=\"2\")\n",
    "\n",
    "SpTrainTask1, SpDevTask1 = reader_train.get(lang=\"ES\", subtask=\"1\"), reader_dev.get(lang=\"ES\", subtask=\"1\")\n",
    "SpTrainTask2, SpDevTask2 = reader_train.get(lang=\"ES\", subtask=\"2\"), reader_dev.get(lang=\"ES\", subtask=\"2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVo9sG1zi1M6"
   },
   "source": [
    "# ENGLISH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u79pF-iWi1M7"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0NHgFNpi1M9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "web_re = re.compile(r\"https?:\\/\\/[^\\s]+\", re.U)\n",
    "user_re = re.compile(r\"(@\\w+\\-?(?:\\w+)?)\", re.U)\n",
    "hashtag_re = re.compile(r\"(#\\w+\\-?(?:\\w+)?)\", re.U)\n",
    "\n",
    "mapLabelToId = {\"task1\": {'NO': 0, 'YES': 1, \"AMBIGUOUS\": 2},\n",
    "                \"task2\": {'-': 4, 'JUDGEMENTAL': 0, 'REPORTED': 1, 'DIRECT': 2, 'UNKNOWN': 3, \"AMBIGUOUS\": 5},\n",
    "                \"task3\": {'OBJECTIFICATION': 0, 'STEREOTYPING-DOMINANCE': 1, 'MISOGYNY-NON-SEXUAL-VIOLENCE': 2,\n",
    "                          'IDEOLOGICAL-INEQUALITY': 3, 'SEXUAL-VIOLENCE': 4, 'UNKNOWN': 5, '-': 6,\n",
    "                          \"AMBIGUOUS\": 7}}\n",
    "\n",
    "mapIdToLabel = {\"task1\": {0: 'NO', 1: 'YES', 2: \"AMBIGUOUS\"},\n",
    "                \"task2\": {4: '-', 0: 'JUDGEMENTAL', 1: 'REPORTED', 2: 'DIRECT', 3: 'UNKNOWN', 4: \"AMBIGUOUS\"},\n",
    "                \"task3\": {0: 'OBJECTIFICATION', 1: 'STEREOTYPING-DOMINANCE', 2: 'MISOGYNY-NON-SEXUAL-VIOLENCE',\n",
    "                          3: 'IDEOLOGICAL-INEQUALITY', 4: 'SEXUAL-VIOLENCE', 5: 'UNKNOWN', 6: '-',\n",
    "                          7: \"AMBIGUOUS\"}}\n",
    "\n",
    "\n",
    "def standard_preprocession(text):\n",
    "    text = web_re.sub(\"\", text)\n",
    "    text = user_re.sub(\"\", text)\n",
    "    text = hashtag_re.sub(\"\", text)\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def no_preprocession(text):\n",
    "    return text\n",
    "\n",
    "def unpack(data, task):\n",
    "    id,text, label = data\n",
    "    id = [id.iloc[i] for i in range(len(id))]\n",
    "    sptext = [standard_preprocession(text.iloc[i]) for i in range(len(text))]\n",
    "\n",
    "    label = [mapLabelToId[task][label.iloc[i]] for i in range(len(label))]\n",
    "\n",
    "    return {\"id\": id, \"sptext\": sptext, \"label\": label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGUjwyJHi1M_"
   },
   "source": [
    "## Tweet representations (Feature extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0as7P7dAi1NA",
    "outputId": "64bd50ed-e41a-4b0b-c16a-b1b60ec26766"
   },
   "outputs": [],
   "source": [
    "# Obtaining a representation for the train and dev subsets in both tasks\n",
    "if torch.backends.mps.is_available():  # Mac M? GPU\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():  # Nvidia GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "else:  # CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBEQHaF-jzO_"
   },
   "outputs": [],
   "source": [
    "def get_contextual_embeddings(text, model_name):\n",
    "    batch_size = 16\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name) #\"roberta-base\"\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    tensor_list=[]\n",
    "    for i in range(0, len(text), batch_size):\n",
    "        batch = text[i:i+batch_size]\n",
    "\n",
    "        input = tokenizer(batch, padding=\"max_length\", max_length = 100, truncation=True, return_tensors=\"pt\")\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        input = input.to(device)\n",
    "        with torch.no_grad():\n",
    "          outputs = model(**input)\n",
    "          encoded_layers = outputs[0]\n",
    "          cls_vector = encoded_layers[:,0,:]\n",
    "\n",
    "        tensor_list.append(cls_vector)\n",
    "    cls_vector = torch.cat(tensor_list).cpu()\n",
    "    return cls_vector\n",
    "\n",
    "\n",
    "# LSA based on TF-IDF of words (100 singular values)\n",
    "def LSA_TF_IDF_repre(data, model_name, lang):\n",
    "    if lang == \"english\":\n",
    "        stop_words = \"english\"\n",
    "    elif lang == \"spanish\":\n",
    "        stop_words = stopwords.words(\"spanish\")\n",
    "    else:\n",
    "        stop_words = None\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words = stop_words, binary=False, use_idf=True, preprocessor=None)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "    num_features = tfidf_matrix.shape[1]\n",
    "    n_components = min(100, num_features)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    svd_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "    return svd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUPHvK1-X_Ge"
   },
   "outputs": [],
   "source": [
    "def get_repre(train, test, method, model_name, task, lang, sample_size = -1):\n",
    "    train_data1 = unpack(train, task)\n",
    "    test_data1 = unpack(test, task)\n",
    "\n",
    "    if sample_size != -1:\n",
    "      for data in [train_data1, test_data1]:\n",
    "          for key, valie in data.items():\n",
    "            data[key] = data[key][:sample_size]\n",
    "\n",
    "    train_data1[\"repre\"] = method(train_data1[\"sptext\"], model_name, lang)\n",
    "    test_data1[\"repre\"] = method(test_data1[\"sptext\"], model_name, lang)\n",
    "\n",
    "    return train_data1, test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkIgiHRPn3wi",
    "outputId": "486b16e2-f66c-43cf-b669-3e78b367d6d2"
   },
   "outputs": [],
   "source": [
    "train_con_embed, test_con_embed = get_repre(EnTrainTask1, EnDevTask1,\n",
    "                                      get_contextual_embeddings, \"roberta-base\",\n",
    "                                            \"task1\",\"english\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u69VksyAn4vz"
   },
   "outputs": [],
   "source": [
    "train_lsa_repre, test_lsa_repre = get_repre(EnTrainTask1, EnDevTask1,\n",
    "                                      LSA_TF_IDF_repre, \"\",\n",
    "                                      \"task1\",\"english\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRH02d5Fi1ND"
   },
   "source": [
    "## Learning Models - subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dowaagWji1NG"
   },
   "outputs": [],
   "source": [
    "def log_reg(x_train, y_train, x_dev, y_dev):\n",
    "    clf1 = LogisticRegression(\n",
    "      penalty='l2',\n",
    "      C=1.0,\n",
    "      solver='liblinear', #'saga' 'l1'\n",
    "      max_iter=200\n",
    "    )\n",
    "    clf1.fit(x_train, y_train)\n",
    "    predicted1 = clf1.predict(x_dev)\n",
    "\n",
    "    f1_positive = f1_score(y_dev, predicted1, pos_label=1)\n",
    "    print(f\"F1-score (Positive Class): {f1_positive}\")\n",
    "\n",
    "    report = classification_report(y_dev,predicted1, digits=4)\n",
    "    print(report)\n",
    "\n",
    "def decision_tree_sub1(X_train, y_train, X_dev, y_dev):\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_dev)\n",
    "\n",
    "    f1_positive = f1_score(y_dev, predicted, pos_label=1)\n",
    "    print(f\"F1-score (Positive Class): {f1_positive}\")\n",
    "\n",
    "    report = classification_report(y_dev,predicted, digits=4)\n",
    "    print(report)\n",
    "\n",
    "def MLP_sub1(X_train, y_train, X_dev, y_dev):\n",
    "    clf = MLPClassifier(random_state = 1,\n",
    "                        hidden_layer_sizes = (256, 128),\n",
    "                        activation='relu',\n",
    "                        max_iter = 1500,\n",
    "                        learning_rate_init = 0.0005,\n",
    "                        alpha=0.0001,\n",
    "                        early_stopping=True,\n",
    "                        solver='lbfgs') # adam\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_dev)\n",
    "\n",
    "    f1_positive = f1_score(y_dev, predicted, pos_label=1)\n",
    "    print(f\"F1-score (Positive Class): {f1_positive}\")\n",
    "\n",
    "    report = classification_report(y_dev, predicted, digits=4)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7i1aAf6TmBLE"
   },
   "outputs": [],
   "source": [
    "def train(train_data, test_data, method):\n",
    "    method(train_data[\"repre\"], train_data[\"label\"],\n",
    "           test_data[\"repre\"], test_data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCE22gFxh8L5"
   },
   "source": [
    "# Subtask 1 - Results - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6nvaahpdl9_",
    "outputId": "92c2ae08-dc7a-4641-ac50-ab7177dcdad2"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_lsa_repre, test_lsa_repre, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkDz6exXhlC4",
    "outputId": "c811aa2b-8c50-4c89-8436-81fa4609529b"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_con_embed, test_con_embed, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwXxqwyTdled",
    "outputId": "ad773048-3107-4937-e92a-6a92386bd85b"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_lsa_repre, test_lsa_repre, decision_tree_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsGPe9VmlC4n",
    "outputId": "abd8d83f-ae99-4990-f4c3-b4b9530067d7"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_con_embed, test_con_embed, decision_tree_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGte0JJgf1O5",
    "outputId": "0d31b5b8-e53e-43f1-c62a-74da261ea3dd"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_lsa_repre, test_lsa_repre, MLP_sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZ1Psr07gA-I",
    "outputId": "6c71a8d1-0b60-4fa3-f172-fa7b5dcec3de"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_con_embed, test_con_embed, MLP_sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSVss5dfiKu5"
   },
   "source": [
    "# Learning Models - Subtask 2 - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdoAfEiciOeS",
    "outputId": "6091fef4-2cd1-4ddd-c32c-7d4c0856c885"
   },
   "outputs": [],
   "source": [
    "train_con_embed2, test_con_embed2 = get_repre(EnTrainTask2, EnDevTask2,\n",
    "                                      get_contextual_embeddings, \"roberta-base\",\n",
    "                                            \"task2\", \"english\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0WDNxwcr_Hj"
   },
   "outputs": [],
   "source": [
    "train_lsa_repre2, test_lsa_repre2 = get_repre(EnTrainTask2, EnDevTask2,\n",
    "                                      LSA_TF_IDF_repre, \"\",\n",
    "                                      \"task2\", \"english\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GnQ1_L7qB-p"
   },
   "outputs": [],
   "source": [
    "def log_reg_sub2(x_train, y_train, x_dev, y_dev):\n",
    "    clf = LogisticRegression(\n",
    "      penalty='l2',\n",
    "      C=1.0,\n",
    "      solver='liblinear', #'saga' 'l1'\n",
    "      max_iter=200\n",
    "    )\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_dev)\n",
    "\n",
    "    f1_macro = f1_score(y_dev, predicted, average='macro')\n",
    "    print(f\"F1-score (Macro-Averaged): {f1_macro}\")\n",
    "\n",
    "    report = classification_report(y_dev,predicted, digits=4)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "def decision_tree_sub2(X_train, y_train, X_dev, y_dev):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_dev)\n",
    "\n",
    "    f1_macro = f1_score(y_dev, predicted, average='macro')\n",
    "    print(f\"F1-score (Macro-Averaged): {f1_macro}\")\n",
    "\n",
    "    report = classification_report(y_dev, predicted, digits=4)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "def MLP_sub2(X_train, y_train, X_dev, y_dev):\n",
    "    clf = MLPClassifier(random_state = 1,\n",
    "                        max_iter = 1500,\n",
    "                        learning_rate_init = 0.0005,\n",
    "                        early_stopping=True,\n",
    "                        solver='lbfgs')\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_dev)\n",
    "\n",
    "    f1_macro = f1_score(y_dev, predicted, average='macro')\n",
    "    print(f\"F1-score (Macro-Averaged): {f1_macro}\")\n",
    "\n",
    "    report = classification_report(y_dev, predicted, digits=4)\n",
    "    print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCR9NkCf7p42"
   },
   "source": [
    "# Subtask 2 - Results - English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0q7mbAltc8H",
    "outputId": "33e208d5-2903-43b6-9c7f-8f08f3f97040"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_lsa_repre2, test_lsa_repre2, log_reg_sub2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVu0BjTmuQnU",
    "outputId": "ec676dbd-5fe3-44c4-bcee-58ea8d0d4fb8"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_con_embed2, test_con_embed2, log_reg_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OhtNSK5uRnR",
    "outputId": "eff85008-1d55-4410-b389-9c859e728e01"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_lsa_repre2, test_lsa_repre2, decision_tree_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKOpWvrYuSPw",
    "outputId": "09e33b74-8955-4419-8d63-2118ee434545"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_con_embed2, test_con_embed2, decision_tree_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByM_UDzmuS1i",
    "outputId": "4e70afd8-61c4-497e-d97c-0f5a9141f21e"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_lsa_repre2, test_lsa_repre2, MLP_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thFSdsK8uTaT",
    "outputId": "475dd215-1ca7-48cd-ec0e-95e060e973a7"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_con_embed2, test_con_embed2, MLP_sub2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5qoprUZi1NM"
   },
   "source": [
    "# SPANISH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "netKRTY8i1NO"
   },
   "source": [
    "## Tweet representations (Feature extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362,
     "referenced_widgets": [
      "79555db4b4a0490285ae56ba090a6b38",
      "3d1f861074a34d4eaeb72bf4a595e20f",
      "e1c011978bf94652bb0bcae2d56dbf5d",
      "b06f7f20bb4b484988f565cfcd723112",
      "12f382310a86495a82f38a954cb618f2",
      "3df92015f29b484ca0c65dfc312cf574",
      "46963992e03e4ea7be43a62112034465",
      "0458ee15f0bd4ff1ab5dd9dc7ba8b3ca",
      "c022053eb5ee47bc98229928f943e77d",
      "a9e9a23cc90c45aab57f4ead2bef2f74",
      "39d3db1d1b674ff5bf4d3245248b3fdb",
      "33971e6aa90041f1a265c3c56d05ef57",
      "95ef6be584244a12b894a7aed68025ce",
      "cd8bb5336fba415a8ae0112736fa88d9",
      "97e1b9027cf14a60a48bbac3795646e7",
      "572b684c65a24be9848ba8c480ea0e58",
      "916c8a33f3bd4be599bfc888caccda2f",
      "b60af9caec214a8ca7739dccca883cdd",
      "48499c4e3966445a8ff9589f99a380ef",
      "fdd53fee91734aa485082fd07551ec19",
      "66aa132b88e642e5b4a5bfa937240627",
      "be822981f2554719a6092475db7daaad",
      "cbe8ab1547ce4b79b3f8bed6e09f355e",
      "3dfc2ea6e1434f14b4e47a998fdebb87",
      "45e21c17a30e499694c7e7150c6104c8",
      "09bc11874451484282651d275a6b3cc6",
      "c7566aae6d134379a236affdc3a13cac",
      "1223e6ab320941b3986a844e05f12d22",
      "87622c03312e48168c7abc031e332d42",
      "7956707d52724171b23e8b98599494ef",
      "595af594a93c41c1b1ead6e5663e0221",
      "f7351ec6d0784732a811945ff422d03c",
      "a54b9f088b6d4ae39e10e4abd30c812e",
      "5349d16c970246ddb4d3688c3a4940a0",
      "52a49177ba6545629b03b5bb22f8c03a",
      "a70fbf460d17410dbaabe93b3ffdde94",
      "55cc303469a2428f9d4d18c5a75174db",
      "a1bb3bfca3d14747bdfd178dd32d699b",
      "27ce5c00c3c0462ebe49a0a5d31a5541",
      "f8ccb1928e7d453dae0862ef1efa1f74",
      "21b7d584fd2d44d1bd7eed3140bb88b1",
      "057c6e90cb8d4ceaa32ac1a53ad5d9d3",
      "536d1eaa0e174d23903b6b89c894e0ef",
      "37c18939ea77410ea3d61737874f7527",
      "77ddc16d6a0949e7b0228eeb3144c771",
      "c64f3487f5b745658c1e57181386d66a",
      "f8af93d0645b4454baa8b07adafe8061",
      "61b630b862e94372bf26f823cea5c6a1",
      "060be8f4157645149c699405014e12e9",
      "d6164040002b4f1994027bcbe5a69866",
      "888e88b0b60840dfa0aa396ea2357dd4",
      "2d97b06bfec742599cdfe7876ea8800c",
      "f26efaee67564fc88d1e55f5a625fb43",
      "f0ce298150d149c28d4b75d13e1ce353",
      "4d3367e91bc84e73bebf45ad59c85bed",
      "18617189a1794a348cfb10bbd5214535",
      "937e39b69c2740fdbcdf7835e718d53e",
      "ba2080867fa14a7eaccc31002ba0c57c",
      "78647125a99a404a9b9545e851771441",
      "a8cec013835b4040aa52b10ca86aae22",
      "776ebac2874043cabedbd6b14feb2c76",
      "b5d92154cee64c37b65bd37d2fc21025",
      "96bbc5e792704baeb1cebf339eb1b385",
      "4e7addf4cc8d42e690c74708e6353164",
      "7c28aa40751e406cb20658e220e661f9",
      "32ef0a17b32642b389005ec502617b56",
      "c606c39ca4a2490aab1ec5804c749aed",
      "ebebcb8a5586429da24d8c380b76667f",
      "993694704ad24fa4bcc2313ffaa40e05",
      "8f57bfff5e6641f8900e7badf76a29d5",
      "ff70e2f80cc54d25b9c85e56ae61c876",
      "e1a97bbb847a406b9bc7fea72ea76145",
      "58bc6ea66bdf480a90dae508a1ea3445",
      "80158e4669de44f5ac14d2687a947edd",
      "7fed124f837842d0afefe9c98e153158",
      "c3d946f1144c4fb2a0d5eae78e501bb3",
      "9ca116f7e63440e8aac4c42e144fb7d4",
      "c5330e3518164bd6abee0fc307f98de3",
      "d2bc75b074c14806a39dfcb7e0f82364",
      "f1882e001d5d44aea222c84f42220026",
      "50705c6b356a4b7ab6ec998433e6b720",
      "c3a3de9d2e5548d3a4481884b1b45ed1",
      "dd5a09ef13694f458da17d2acba31947",
      "243ab88126514f16b4680f7025985a77",
      "193a5c6bf9d84a7cb6e4676aee86a040",
      "cba58a2cf77e49e0b96c89f55d60afae",
      "ce67a6e6c05e42cf9fb561c2b1eb74f8",
      "b6088f151c884d0fab355e2b48db08e8"
     ]
    },
    "id": "B0hCgI1ji1NO",
    "outputId": "3aa76250-ca57-4891-b57f-e0685f35af8c"
   },
   "outputs": [],
   "source": [
    "train_con_embed, test_con_embed = get_repre(SpTrainTask1, SpDevTask1,\n",
    "                                      get_contextual_embeddings, \"PlanTL-GOB-ES/roberta-base-bne\",\n",
    "                                            \"task1\", \"spanish\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GEHgzrM0BXc"
   },
   "outputs": [],
   "source": [
    "train_lsa_repre, test_lsa_repre = get_repre(SpTrainTask1, SpDevTask1,\n",
    "                                      LSA_TF_IDF_repre, \"\",\n",
    "                                      \"task1\", \"spanish\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2z-U9azi1NQ"
   },
   "source": [
    "## Subtask 1 - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9Emjs6Zi1NR",
    "outputId": "fa9dd90b-b558-4965-9e3a-7ff75245151a"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_lsa_repre, test_lsa_repre, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjWunY-m1Yn1",
    "outputId": "897e100b-06c7-4ac6-98d4-14dec9839cb3"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_con_embed, test_con_embed, log_reg) #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFirIqq-1aP3",
    "outputId": "85fef9ec-b346-4ea2-e19d-3576834ddf74"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_lsa_repre, test_lsa_repre, decision_tree_sub1) #51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4v4NyzS1bFi",
    "outputId": "666c10b7-75fb-45ad-e4b3-32fed209dfb7"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_con_embed, test_con_embed, decision_tree_sub1) #42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2pZ6v181b4D",
    "outputId": "5ef3d7b3-e0e3-4e95-c181-3ac3a6330f64"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_lsa_repre, test_lsa_repre, MLP_sub1) #50 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7YkxP-21dCd",
    "outputId": "d8d83965-3bff-44c4-fa70-b3361dce7a56"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_con_embed, test_con_embed, MLP_sub1) #38 74\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzN2p6f8iCU_"
   },
   "source": [
    "# Subtask 2 - Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Kv384wbiBEO",
    "outputId": "9254055a-7732-4bd4-adb6-3b5e93336ff1"
   },
   "outputs": [],
   "source": [
    "train_con_embed2_sp, test_con_embed2_sp = get_repre(SpTrainTask2, SpDevTask2,\n",
    "                                      get_contextual_embeddings, \"PlanTL-GOB-ES/roberta-base-bne\",\n",
    "                                            \"task2\", \"spanish\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BABb0AQwiHpx"
   },
   "outputs": [],
   "source": [
    "train_lsa_repre2_sp, test_lsa_repre2_sp = get_repre(SpTrainTask2, SpDevTask2,\n",
    "                                      LSA_TF_IDF_repre, \"\",\n",
    "                                      \"task2\", \"spanish\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syG4SygDidYL",
    "outputId": "cb3e65f2-bfa5-4432-eb6e-a4d88f3478e6"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_lsa_repre2_sp, test_lsa_repre2_sp, log_reg_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQRCQZ4akk3f",
    "outputId": "d3927b57-a97c-4e87-96e7-bcbc78098c43"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Logistic regression\")\n",
    "train(train_con_embed2_sp, test_con_embed2_sp, log_reg_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Vg331XJkmMT",
    "outputId": "d0fe3b6b-aead-45c6-ca57-4e44865a5f22"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_lsa_repre2_sp, test_lsa_repre2_sp, decision_tree_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIBqPaTCkneA",
    "outputId": "408d15d8-0786-4740-8105-ff26c8fd1339"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: Decison Tree\")\n",
    "train(train_con_embed2_sp, test_con_embed2_sp, decision_tree_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yll6MbxQkosT",
    "outputId": "74311633-ff00-448a-8160-4dfe0449db10"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: LSA based on TD-IDF with 50 components\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_lsa_repre2_sp, test_lsa_repre2_sp, MLP_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fovx4RbDkpva",
    "outputId": "dd729e7d-9de0-4883-9d6c-7ec548d304da"
   },
   "outputs": [],
   "source": [
    "print(\"Representation: Contextual embeddings using RoBERTa\")\n",
    "print(\"Clasiffier: MLP\")\n",
    "train(train_con_embed2_sp, test_con_embed2_sp, MLP_sub2)  #54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "* Subtask 1 English\n",
    "  * Logistic regresion is the best one, almost tied with MLP, which is second. DT is much worse\n",
    "  * Contextual embeddings perform much better that LSA based TF-IDF, which is understandable, because they took much longer to compute\n",
    "\n",
    "* Subtask 2 English\n",
    "  * this subtask is much harder, with significantly lower F1 scores\n",
    "  * generally, MLP is the best one, followed with DT, but LSA based works the best with DT and contextual embeddings work the best with MLP\n",
    "\n",
    "* Subtask 1 Spanish\n",
    "  * results from subtask 1 english also apply here\n",
    "  * LR with contextual embeddings got the highest F1 score, I managed to achieve - 0.81\n",
    "\n",
    "* Subtask 2 Spanish\n",
    "  * MLP is again best, but the differences with LR are smaller\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lRH02d5Fi1ND",
    "wCE22gFxh8L5",
    "HSVss5dfiKu5",
    "Y9O6j0w4i1NI",
    "PZRjGUdKi1NM",
    "netKRTY8i1NO",
    "U2z-U9azi1NQ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
